{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet with Resnet 50 Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch -q\n",
    "# %pip install opencv-python -q\n",
    "# %pip install pycocotools -q\n",
    "# %pip install timm==0.6.12 -q\n",
    "# %pip install ipdb -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "import sys\n",
    "import wandb\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add more items here\n",
    "config = {\n",
    "    \"lr\"         : 1e-4,\n",
    "    \"epochs\"     : 100,\n",
    "    \"batch_size\" : 1,  # Increase if your device can handle it\n",
    "    \"num_classes\": 1,\n",
    "    'truncated_normal_mean' : 0,\n",
    "    'truncated_normal_std' : 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "# create a torch.utils.data.Dataset/DataLoader\n",
    "annotation_json_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/round_1/annotations.json'\n",
    "train_img_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/round_1/images-clean'\n",
    "train_mask_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/round_1/masks-clean'\n",
    "\n",
    "#! Temporarily using train and val images as same\n",
    "val_img_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/sensors_2023-08-03-15-19-03_0/images'\n",
    "val_mask_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/sensors_2023-08-03-15-19-03_0/masks'\n",
    "\n",
    "test_img_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/sensors_2023-08-03-15-19-03_0/images'\n",
    "\n",
    "# img_size = (1384, 1032) # = width, height            # currently PtGrey images\n",
    "img_size = (1024, 1024)\n",
    "\n",
    "checkpoint_path = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/checkpoints/checkpoint.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Masks from the COCO annotations (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_coco_to_mask(input_json=annotation_json_path, image_folder=train_img_path, output_folder=train_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean and std of your dataset:\n",
    "def get_mean_and_std_calculated(IMAGE_DATA_DIR):\n",
    "    \"\"\"\n",
    "    NOTE: The ImageFolder dataloader requires the following file structure:\n",
    "\n",
    "    root\n",
    "    |\n",
    "    └── cat (class label)\n",
    "        |\n",
    "        ├──img_2.png\n",
    "        └──img_1.png\n",
    "\n",
    "    \"\"\"\n",
    "    train_dataset = ImageFolder(IMAGE_DATA_DIR, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "    # Initialize lists to store channel-wise means and standard deviations\n",
    "    channel_wise_means = [0.0, 0.0, 0.0]\n",
    "    channel_wise_stds = [0.0, 0.0, 0.0]\n",
    "\n",
    "    # Iterate through the training dataset to calculate means and standard deviations\n",
    "    for image, _ in train_dataset:\n",
    "        for i in range(3):  # Assuming RGB images\n",
    "            channel_wise_means[i] += image[i, :, :].mean().item()\n",
    "            channel_wise_stds[i] += image[i, :, :].std().item()\n",
    "\n",
    "    # Calculate the mean and standard deviation for each channel\n",
    "    num_samples = len(train_dataset)\n",
    "    channel_wise_means = [mean / num_samples for mean in channel_wise_means]\n",
    "    channel_wise_stds = [std / num_samples for std in channel_wise_stds]\n",
    "\n",
    "    # Print the mean and standard deviation for each channel\n",
    "    print(\"Mean:\", channel_wise_means)\n",
    "    print(\"Std:\", channel_wise_stds)\n",
    "\n",
    "    return channel_wise_means, channel_wise_stds\n",
    "\n",
    "# means, stds = get_mean_and_std_calculated(train_img_path_for_ImageFolder_dataloader)\n",
    "means = [0.44895144719250346, 0.4951483853617493, 0.4498602793532975]\n",
    "stds = [0.21388493326245522, 0.24571933703763144, 0.22413276759337405]\n",
    "\n",
    "normalize_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Normalize(mean=means, std=stds) # always normalize only after tensor conversion\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 img_paths,\n",
    "                 mask_paths=None,\n",
    "                 size=(256, 256),\n",
    "                 mode='binary',\n",
    "                 normalize=None,\n",
    "                 transformations=None):\n",
    "        \n",
    "        self.img_paths = sorted(os.listdir(img_paths))\n",
    "        self.img_paths = [os.path.join(img_paths, img_path) for img_path in self.img_paths]\n",
    "        if mask_paths is not None:\n",
    "            self.mask_paths = sorted(os.listdir(mask_paths))\n",
    "            self.mask_paths = [os.path.join(mask_paths, mask_path) for mask_path in self.mask_paths]\n",
    "        else:\n",
    "            self.mask_paths = None\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        self.normalize = normalize\n",
    "        self.transformations = transformations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\") \n",
    "\n",
    "        numpy_img = np.array(img, dtype=np.uint8).transpose((2, 0, 1)) \n",
    "        img = numpy_img[:, 8:, 240:-120]\n",
    "        img = Image.fromarray(img.transpose((1, 2, 0)))\n",
    "        img = self.transformations(img) if (self.transformations is not None) else img\n",
    "\n",
    "        img = torch.Tensor(img) \n",
    "\n",
    "        img = self.normalize(img) if self.normalize is not None else img\n",
    "\n",
    "        if self.mask_paths is not None:\n",
    "            mask_path = self.mask_paths[index]\n",
    "            mask = Image.open(mask_path)\n",
    "\n",
    "            mask = np.array(mask, dtype=np.uint8) \n",
    "\n",
    "            mask = mask[8:, 240:-120]\n",
    "\n",
    "            mask[:, :][mask[:, :] >= 1] = 1\n",
    "            mask[:, :][mask[:, :] < 1] = 0 \n",
    "            mask = np.expand_dims(mask, axis=0)\n",
    "            mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "            return img, mask\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    # To PIL Image\n",
    "    # torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.16, contrast=0.15, saturation=0.1),\n",
    "    torchvision.transforms.RandomRotation(18),\n",
    "    torchvision.transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    torchvision.transforms.RandomPerspective(distortion_scale=0.2, p=0.2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(img_paths=train_img_path, mask_paths=train_mask_path, size=img_size, mode='binary', normalize=normalize_transform, transformations=train_transforms)\n",
    "val_dataset = SemanticSegmentationDataset(img_paths=val_img_path, mask_paths=val_mask_path, size=img_size, mode='binary', normalize=normalize_transform, transformations=val_transforms)\n",
    "test_dataset = SemanticSegmentationDataset(img_paths=val_img_path, mask_paths=None, size=img_size, normalize=normalize_transform, transformations=test_transforms)\n",
    "\n",
    "temp = train_dataset.__getitem__(1)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = False,\n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset     = test_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = False,\n",
    "    drop_last   = False,\n",
    "    num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Model\n",
    "\n",
    "reference: https://github.com/mberkay0/pretrained-backbones-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            backbone='resnet50',\n",
    "            encoder_freeze=False,\n",
    "            pretrained=True,\n",
    "            preprocessing=False,\n",
    "            non_trainable_layers=(0, 1, 2, 3, 4),\n",
    "            backbone_kwargs=None,\n",
    "            backbone_indices=None,\n",
    "            decoder_use_batchnorm=True,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            in_channels=3,\n",
    "            num_classes=1,\n",
    "            center=False,\n",
    "            norm_layer=nn.BatchNorm2d,\n",
    "            activation=nn.ReLU\n",
    "    ):\n",
    "        super().__init__()\n",
    "        backbone_kwargs = backbone_kwargs or {}\n",
    "\n",
    "        encoder = create_model(\n",
    "            backbone, features_only=True, out_indices=backbone_indices, \n",
    "            in_chans=in_channels, pretrained=pretrained, **backbone_kwargs\n",
    "        )\n",
    "        encoder_channels = [info[\"num_chs\"] for info in encoder.feature_info][::-1]\n",
    "        self.encoder = encoder\n",
    "        if preprocessing:\n",
    "            self.mean = self.encoder.default_cfg[\"mean\"] \n",
    "            self.std = self.encoder.default_cfg[\"std\"]\n",
    "        else:\n",
    "            self.mean = None\n",
    "            self.std = None\n",
    "\n",
    "        if not decoder_use_batchnorm:\n",
    "            norm_layer = None\n",
    "        self.decoder = UnetDecoder(\n",
    "            encoder_channels=encoder_channels,\n",
    "            decoder_channels=decoder_channels,\n",
    "            final_channels=num_classes,\n",
    "            norm_layer=norm_layer,\n",
    "            center=center,\n",
    "            activation=activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if self.mean and self.std:\n",
    "            x = self._preprocess_input(x)\n",
    "        x = self.encoder(x)\n",
    "        x.reverse()  \n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x):\n",
    "        if self.training: \n",
    "            self.eval()\n",
    "        x = self.forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _preprocess_input(self, x, input_range=[0, 1], inplace=False):\n",
    "        if not x.is_floating_point():\n",
    "            raise TypeError(f\"Input tensor should be a float tensor. Got {x.dtype}.\")\n",
    "\n",
    "        if x.ndim < 3:\n",
    "            raise ValueError(\n",
    "                f\"Expected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = {x.size()}\"\n",
    "            )\n",
    "\n",
    "        if not inplace:\n",
    "            x = x.clone()\n",
    "\n",
    "        dtype = x.dtype\n",
    "        mean = torch.as_tensor(self.mean, dtype=dtype, device=x.device)\n",
    "        std = torch.as_tensor(self.std, dtype=dtype, device=x.device)\n",
    "        if (std == 0).any():\n",
    "            raise ValueError(f\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\")\n",
    "        if mean.ndim == 1:\n",
    "            mean = mean.view(-1, 1, 1)\n",
    "        if std.ndim == 1:\n",
    "            std = std.view(-1, 1, 1)\n",
    "        return x.sub_(mean).div_(std)\n",
    "\n",
    "# UNet Blocks\n",
    "\n",
    "class Conv2dBnAct(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0,\n",
    "                 stride=1, activation=nn.ReLU, norm_layer=nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, \n",
    "            stride=stride, padding=padding, bias=False\n",
    "        )\n",
    "        self.bn = norm_layer(out_channels)\n",
    "        self.act = activation(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, scale_factor=2.0, \n",
    "        activation=nn.ReLU, norm_layer=nn.BatchNorm2d\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_args = dict(kernel_size=3, padding=1, activation=activation)\n",
    "        self.scale_factor = scale_factor\n",
    "        if norm_layer is None:\n",
    "            self.conv1 = Conv2dBnAct(in_channels, out_channels, **conv_args)\n",
    "            self.conv2 = Conv2dBnAct(out_channels, out_channels,  **conv_args)\n",
    "        else:\n",
    "            self.conv1 = Conv2dBnAct(in_channels, out_channels, norm_layer=norm_layer, **conv_args)\n",
    "            self.conv2 = Conv2dBnAct(out_channels, out_channels, norm_layer=norm_layer, **conv_args)\n",
    "\n",
    "    def forward(self, x, skip= None):\n",
    "        if self.scale_factor != 1.0:\n",
    "            x = F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UnetDecoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_channels,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            final_channels=1,\n",
    "            norm_layer=nn.BatchNorm2d,\n",
    "            center=True,\n",
    "            activation=nn.ReLU\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = DecoderBlock(\n",
    "                channels, channels, scale_factor=1.0, \n",
    "                activation=activation, norm_layer=norm_layer\n",
    "            )\n",
    "        else:\n",
    "            self.center = nn.Identity()\n",
    "\n",
    "        in_channels = [in_chs + skip_chs for in_chs, skip_chs in zip(\n",
    "            [encoder_channels[0]] + list(decoder_channels[:-1]),\n",
    "            list(encoder_channels[1:]) + [0])]\n",
    "\n",
    "        out_channels = decoder_channels\n",
    "\n",
    "        if len(in_channels) != len(out_channels):\n",
    "            in_channels.append(in_channels[-1]//2)\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for in_chs, out_chs in zip(in_channels, out_channels):\n",
    "            self.blocks.append(DecoderBlock(in_chs, out_chs, norm_layer=norm_layer))\n",
    "        self.final_conv = nn.Conv2d(out_channels[-1], final_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "        x = self.center(encoder_head)\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            skip = skips[i] if i < len(skips) else None\n",
    "            x = b(x, skip)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, from_logits=False, smooth=1e-7, eps=1e-7, reduction=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.from_logits = from_logits\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        if not self.from_logits: y_pred = F.sigmoid(y_pred) \n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_true = y_true.view(-1)\n",
    "        \n",
    "        intersection = torch.sum(y_pred * y_true)\n",
    "        cardinalities = torch.sum(y_pred + y_true) + self.smooth                           \n",
    "        dice = (2.0 * intersection + self.smooth) / (cardinalities + self.smooth).clamp_min(self.eps) \n",
    "        loss = 1 - dice\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        elif self.reduction is None:\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception('Unexpected reduction {}'.format(self.reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(\n",
    "    # backbone='convnext_base', # backbone network name\n",
    "    backbone='resnet50',\n",
    "    preprocessing=True,\n",
    "    in_channels=3, # input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    num_classes=config[\"num_classes\"],  # output channels (number of classes in your dataset)\n",
    "    encoder_freeze=True,\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "# model = model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiyoonp\u001b[0m (\u001b[33mjiyooonp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jy/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/wandb/run-20231213_090809-zntk6c33</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jiyooonp/IDL_Project_Segmentation/runs/zntk6c33' target=\"_blank\">UNet_with_resnet_50</a></strong> to <a href='https://wandb.ai/jiyooonp/IDL_Project_Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jiyooonp/IDL_Project_Segmentation' target=\"_blank\">https://wandb.ai/jiyooonp/IDL_Project_Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jiyooonp/IDL_Project_Segmentation/runs/zntk6c33' target=\"_blank\">https://wandb.ai/jiyooonp/IDL_Project_Segmentation/runs/zntk6c33</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define wandb credentials\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f04483494d6e038d151d85781642caafd264d7c4\") #API Key is in your wandb account, under settings (wandb.ai/settings)\n",
    "\n",
    "run = wandb.init(\n",
    "    name = \"UNet_with_resnet_50\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"IDL_Project_Segmentation\", ### Project should be created in your wandb account\n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|\u001b[32m██████████\u001b[0m| 536/536 [01:51<00:00,  4.80 training-batch/s, loss=0.398]\n",
      "Validation: 100%|\u001b[32m██████████\u001b[0m| 98/98 [00:06<00:00, 14.17 validating-batch/s, loss=0.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss 0.2005\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traning Model on 1 epochs: 100%|██████████| 1/1 [01:59<00:00, 119.86s/it]\n"
     ]
    }
   ],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.AdamW(params, lr=config['lr'], betas=(0.9, 0.999), weight_decay=0.05)\n",
    "gamma = 0.8\n",
    "milestones = [10,20,40,60,80]\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "mixed_precision_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,              # UNet model with Resnet50 backbone\n",
    "    criterion=DiceLoss(),     # loss function\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    # scaler=mixed_precision_scaler,\n",
    "    lr_scheduler=scheduler,\n",
    "    device=device,\n",
    "    checkpoint_path=checkpoint_path\n",
    ")\n",
    "\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        scaler=None,\n",
    "        lr_scheduler=None,\n",
    "        device=None,\n",
    "        checkpoint_path=None\n",
    "    ):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scaler = scaler\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = self._get_device(device) if device is None else device\n",
    "        self.epochs = epochs\n",
    "        self.model = model.to(self.device)\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        lowest_val_loss = 1000000\n",
    "\n",
    "        self.train_losses_ = torch.zeros(self.epochs)\n",
    "        self.val_losses_ = torch.zeros(self.epochs)\n",
    "        for epoch in trange(1, self.epochs + 1, desc='Traning Model on {} epochs'.format(self.epochs)):\n",
    "            self._train_one_epoch(train_loader, epoch)\n",
    "            self._evaluate(val_loader, epoch)\n",
    "\n",
    "            val_loss = self.val_losses_[epoch-1]\n",
    "            train_loss = self.train_losses_[epoch-1]\n",
    "\n",
    "            print(\"Val Loss {:.04f}\".format(val_loss))\n",
    "\n",
    "            curr_lr = float(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            wandb.log({\"train_loss\":train_loss, 'validation_loss': val_loss, \"learning_Rate\": curr_lr})\n",
    "\n",
    "            if val_loss <= lowest_val_loss and self.checkpoint_path is not None:\n",
    "                print(\"Saving model\")\n",
    "                torch.save({'model_state_dict':self.model.state_dict(),\n",
    "                            'optimizer_state_dict':self.optimizer.state_dict(),\n",
    "                            'scheduler_state_dict':self.lr_scheduler.state_dict(),\n",
    "                            'val_loss': val_loss,\n",
    "                            'epoch': epoch}, './checkpoint.pth')\n",
    "                torch.save({'model_state_dict':self.model.state_dict(),\n",
    "                            'optimizer_state_dict':self.optimizer.state_dict(),\n",
    "                            'scheduler_state_dict':self.lr_scheduler.state_dict(),\n",
    "                            'val_loss': val_loss,\n",
    "                            'epoch': epoch}, self.checkpoint_path)\n",
    "                lowest_val_loss = val_loss\n",
    "                wandb.save('checkpoint.pth')\n",
    "\n",
    "\n",
    "    def _train_one_epoch(self, data_loader, epoch):\n",
    "        self.model.train()\n",
    "        losses = torch.zeros(len(data_loader))\n",
    "        with tqdm(data_loader, unit=\" training-batch\", colour=\"green\") as training:\n",
    "            for i, (images, labels) in enumerate(training):\n",
    "                training.set_description(f\"Epoch {epoch}\")\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                with torch.cuda.amp.autocast(enabled=self.scaler is not None):\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds.float(), labels.float())\n",
    "                if not math.isfinite(loss):\n",
    "                    msg = f\"Loss is {loss}, stopping training!\"\n",
    "                    warnings.warn(msg)\n",
    "                    sys.exit(1)\n",
    "                self.optimizer.zero_grad()\n",
    "                if self.scaler is not None:\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "\n",
    "                training.set_postfix(loss=loss.item())\n",
    "                losses[i] = loss.item()\n",
    "\n",
    "            self.train_losses_[epoch - 1] = losses.mean()\n",
    "\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _evaluate(self, data_loader, epoch):\n",
    "        self.model.eval()\n",
    "        losses = torch.zeros(len(data_loader))\n",
    "        with tqdm(data_loader, unit=\" validating-batch\", colour=\"green\") as evaluation:\n",
    "            for i, (images, labels) in enumerate(evaluation):\n",
    "                evaluation.set_description(f\"Validation\")\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds.float(), labels.float())\n",
    "                self.val_losses_[epoch - 1] = loss.item()\n",
    "                evaluation.set_postfix(loss=loss.item())\n",
    "                losses[i] = loss.item()\n",
    "\n",
    "            self.val_losses_[epoch - 1] = losses.mean()\n",
    "\n",
    "\n",
    "    def _get_device(self, _device):\n",
    "        if _device is None:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            msg = f\"Device was automatically selected: {device}\"\n",
    "            warnings.warn(msg)\n",
    "            return device\n",
    "        return _device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scheduler state from checkpoint.\n",
      "Loaded checkpoint from: /home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/checkpoints/checkpoint.pth\n",
      "Unet(\n",
      "  (encoder): FeatureListNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if the checkpoint file exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # If the checkpoint file exists, load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']  # last epoch\n",
    "    val_loss = checkpoint['val_loss']  # Update the best accuracy\n",
    "    # Load the checkpoint and update the scheduler state if it exists in the checkpoint\n",
    "    if 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        print(\"Loaded scheduler state from checkpoint.\")\n",
    "    else:\n",
    "        print(\"No scheduler state found in checkpoint.\")\n",
    "    print(\"Loaded checkpoint from:\", checkpoint_path)\n",
    "else:\n",
    "    # If the checkpoint file does not exist, start training from scratch\n",
    "    start_epoch = 0\n",
    "    print(\"No checkpoint found at:\", checkpoint_path)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "TEST_IMG_PATH = '/home/jy/Desktop/cmu/IDL/project/pretrained-backbones-unet/sensors_2023-08-03-15-19-03_0/images/frame000001.png'\n",
    "\n",
    "test_img = cv2.imread(TEST_IMG_PATH)\n",
    "test_img = cv2.resize(test_img, (1024, 1024))\n",
    "test_img = test_transforms(test_img)\n",
    "test_img = test_img.unsqueeze(0)\n",
    "test_img = test_img.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model.predict(test_img)\n",
    "\n",
    "pred = pred.cpu().numpy()\n",
    "pred = np.squeeze(pred)\n",
    "\n",
    "# Now pred has shape (1024, 1024)\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "pred = pred.astype(np.uint8)\n",
    "pred = pred.astype(np.uint8)\n",
    "\n",
    "plt.imshow(pred, cmap='gray')  # You can specify the colormap if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
